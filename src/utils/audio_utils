import os
import soundfile as sf
import torch
from silero_vad import read_audio, get_speech_timestamps, load_silero_vad
import whisper

AUDIO_SAVE_PATH = "audio_files"
SAMPLE_RATE = 16000
VAD_MODEL = load_silero_vad()
WHISPER_MODEL = whisper.load_model("tiny")


def save_audio_file(file, filename):
    os.makedirs(AUDIO_SAVE_PATH, exist_ok=True)
    filepath = os.path.join(AUDIO_SAVE_PATH, filename)
    with open(filepath, "wb") as f:
        f.write(file.read())
    return filepath


def get_speech_segments(filepath):
    wav = read_audio(filepath, sampling_rate=SAMPLE_RATE)
    speech_timestamps = get_speech_timestamps(wav, VAD_MODEL, return_seconds=True)
    return wav, speech_timestamps


def transcribe_segment(wav, start_time, end_time, segment_id):
    start_sample = int(start_time * SAMPLE_RATE)
    end_sample = int(end_time * SAMPLE_RATE)
    segment_wave = wav[start_sample:end_sample]
    temp_filename = f"temp_segment_{segment_id}.wav"
    sf.write(temp_filename, segment_wave.squeeze().numpy(), SAMPLE_RATE)

    result = WHISPER_MODEL.transcribe(temp_filename)
    os.remove(temp_filename)

    return result["text"], result["language"]
